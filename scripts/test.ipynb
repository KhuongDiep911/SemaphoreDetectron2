{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c554b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "# from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b76e2b",
   "metadata": {},
   "source": [
    "# Register a COCO Format Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "DatasetCatalog.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fec96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"train_dataset\", {}, \"../dataset/FINAL/train/annotation.json\", \"../dataset/FINAL/train\")\n",
    "# register_coco_instances(\"validation_dataset\", {}, \"result.json\", \"path/to/image/dir\")\n",
    "# register_coco_instances(\"test_dataset\", {}, \"result.json\", \"path/to/image/dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dictionary\n",
    "dataset_dicts = DatasetCatalog.get('train_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5168850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "# cfg.MODEL.DEVICE = \"cpu\"\n",
    "# load the pre trained model from Detectron2 model zoo\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
    "# set confidence threshold for this model\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  \n",
    "# load model weights\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model using the image\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1\n",
    "\n",
    "# visualize N number of samples\n",
    "for d in random.sample(dataset_dicts, n_samples):\n",
    "#     filename = d[\"file_name\"].replace('\\\\','/')\n",
    "    print(filename)\n",
    "    \n",
    "    im = cv2.imread(filename)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b7c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_keypoints = outputs[\"instances\"].to(\"cpu\").pred_keypoints.numpy()\n",
    "pred_keypoints[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67099c24",
   "metadata": {},
   "source": [
    "# Create a Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82eacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_df(df, keypoints, classlabel):\n",
    "    temp_dict = dict()\n",
    "    temp_dict['letter'] = classlabel\n",
    "    \n",
    "    for i in range(17):\n",
    "        temp_dict['x'+str(i)] = keypoints[i,0]\n",
    "        temp_dict['y'+str(i)] = keypoints[i,1]\n",
    "    \n",
    "    df = df.append(temp_dict, ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60675c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataframe\n",
    "df = pd.DataFrame(columns = ['x0','y0','x1','y1','x2','y2','x3','y3','x4','y4','x5','y5','x6','y6',\n",
    "                             'x7','y7','x8','y8','x9','y9','x10','y10','x11','y11','x12','y12',\n",
    "                             'x13','y13','x14','y14','x15','y15','x16','y16','letter'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72beac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make inference for each images and assign the corresponding class\n",
    "for d in dataset_dicts:\n",
    "    filename = d[\"file_name\"].replace('\\\\','/')\n",
    "    \n",
    "    im = cv2.imread(filename)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    #get keypoints\n",
    "    pred_keypoints = outputs[\"instances\"].to(\"cpu\").pred_keypoints.numpy()\n",
    "    \n",
    "    #get class label based on the filename\n",
    "    classlabel = filename.rsplit('/')[-1].replace(\".jpg\",\"\")\n",
    "    \n",
    "    #save in the dataframe\n",
    "    df = add_to_df(df, pred_keypoints[0], classlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9087bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d586df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the features and target variable\n",
    "X = df.drop(columns=['letter'])\n",
    "y = df['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ad716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61effd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2idx = {'A': 0, 'B': 1, \"C\": 2, \"D\": 3, 'E': 4, 'F': 5, \"G\": 6, \"H\": 7, 'I': 8, 'J': 9, 'K': 10, \"L\": 11, \"M\": 12, 'N': 13, 'O': 14, 'P': 15, \"Q\": 16, \"R\": 17, 'S': 18, 'T': 19, 'U': 20, \"V\": 21, \"W\": 22, \"X\": 23, 'Y': 24, 'Z': 25, 'SPACE': 26, 'START-STOP': 27}\n",
    "idx2class = {v: k for k, v in class2idx.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb72301",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace(class2idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac1288",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor = torch.tensor(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ec0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73870d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d5352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataloader\n",
    "from torch.utils.data import Dataset, Dataloader\n",
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=X_tensor\n",
    "        self.y=y_tensor\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daed258",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314feb4",
   "metadata": {},
   "source": [
    "### Create classification model using multi-layered perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efd988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, 512)\n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.layer_3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a47119",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323a92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_FEATURES = 34\n",
    "NUM_CLASSES = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1507d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MulticlassClassification(num_feature = NUM_FEATURES, num_class = NUM_CLASSES)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('W:',list(model.parameters())[0].size())\n",
    "print('b',list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc255403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    'val': []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    'val': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8712a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(1, EPOCHS+1):\n",
    "    \n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    \n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    for X_train_batch, y_train_batch in trainloader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # perform prediction\n",
    "        y_train_pred = model(X_train_batch)\n",
    "        \n",
    "        # compute for loss and accuracy\n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "        \n",
    "        # optimization\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        \n",
    "    loss_stats['train'].append(train_epoch_loss/len(trainloader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(trainloader))\n",
    "    \n",
    "    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(trainloader):.5f} | Train Acc: {train_epoch_acc/len(trainloader):.5f})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b70fd89",
   "metadata": {},
   "source": [
    "# Inference using Detectron2 and Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5f6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "# cfg.MODEL.DEVICE = \"cpu\"\n",
    "# load the pre trained model from Detectron2 model zoo\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
    "# set confidence threshold for this model\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  \n",
    "# load model weights\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab3168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im = cv2.imread(\"demo11.jpeg\")\n",
    "\n",
    "def cv2_imshow(im):\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(25,7.5)), plt.imshow(im), plt.axis('off');\n",
    "    \n",
    "# test the model using the image\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_keypoints = outputs[\"instances\"].to(\"cpu\").pred_keypoints.numpy()\n",
    "pred_keypoints[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
